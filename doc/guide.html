

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Programmer’s Guide &mdash; Steam Audio C API  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/steamaudio.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Integrating Steam Audio" href="integration.html" />
    <link rel="prev" title="Getting Started" href="getting-started.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/steam-audio-logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                4.0.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Steam Audio SDK</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Programmer’s Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#initialization">Initialization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#memory-allocation">Memory Allocation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simd-optimizations">SIMD Optimizations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#destroying-steam-audio-api-objects">Destroying Steam Audio API objects</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#audio-buffers">Audio Buffers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#interleaved-vs-deinterleaved-audio">Interleaved vs. deinterleaved audio</a></li>
<li class="toctree-l3"><a class="reference internal" href="#allocating-audio-buffers">Allocating audio buffers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#hrtf">HRTF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loading-an-hrtf">Loading an HRTF</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-hrtfs">Custom HRTFs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#binaural-effect">Binaural Effect</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hrtf-interpolation">HRTF interpolation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spatial-blend">Spatial blend</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#ambisonics">Ambisonics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#encoding-a-point-source-to-ambisonics">Encoding a point source to Ambisonics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decoding-ambisonics-for-rendering">Decoding Ambisonics for rendering</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rotating-ambisonic-sound-fields">Rotating Ambisonic sound fields</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#direct-effect">Direct Effect</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#distance-attenuation">Distance attenuation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#air-absorption">Air absorption</a></li>
<li class="toctree-l3"><a class="reference internal" href="#directivity">Directivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#occlusion-and-transmission">Occlusion and transmission</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scene">Scene</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#static-geometry">Static geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-geometry">Dynamic geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#serializing-scenes">Serializing scenes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-your-own-ray-tracer">Using your own ray tracer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#simulation">Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sources">Sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simulating-occlusion-and-transmission">Simulating occlusion and transmission</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#reflections">Reflections</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#initializing-a-simulator-for-reflections">Initializing a simulator for reflections</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simulating-reflections">Simulating reflections</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rendering-reflections">Rendering reflections</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reverb">Reverb</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#baking">Baking</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#generating-probes">Generating probes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#baking-reflections">Baking reflections</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-baked-reflections-data">Using baked reflections data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pathing">Pathing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#baking-pathing-data">Baking pathing data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-baked-pathing-data">Using baked pathing data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rendering-paths">Rendering paths</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="integration.html">Integrating Steam Audio</a></li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">API Reference</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Steam Audio C API</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Programmer’s Guide</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="programmer-s-guide">
<h1>Programmer’s Guide<a class="headerlink" href="#programmer-s-guide" title="Permalink to this headline">¶</a></h1>
<div class="section" id="initialization">
<h2>Initialization<a class="headerlink" href="#initialization" title="Permalink to this headline">¶</a></h2>
<p>Before using any Steam Audio functionality, you must create an <code class="docutils literal notranslate"><span class="pre">IPLContext</span></code> object. This contains various global settings and data structures used internally by Steam Audio:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLContextSettings</span> <span class="n">contextSettings</span><span class="p">{};</span>

<span class="c1">// this is the version of the Steam Audio API that your program has been compiled against</span>
<span class="n">contextSettings</span><span class="p">.</span><span class="n">version</span> <span class="o">=</span> <span class="n">STEAMAUDIO_VERSION</span><span class="p">;</span>

<span class="c1">// this is a handle to a context object, which we will initialize next</span>
<span class="n">IPLContext</span> <span class="n">context</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>

<span class="n">IPLerror</span> <span class="n">errorCode</span> <span class="o">=</span> <span class="n">iplContextCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">contextSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">context</span><span class="p">);</span>
<span class="k">if</span> <span class="p">(</span><span class="n">errorCode</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// handle the error</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="section" id="memory-allocation">
<h3>Memory Allocation<a class="headerlink" href="#memory-allocation" title="Permalink to this headline">¶</a></h3>
<p>By default, Steam Audio uses the OS aligned memory allocation functions (<code class="docutils literal notranslate"><span class="pre">_aligned_malloc</span></code> on Windows, and <code class="docutils literal notranslate"><span class="pre">posix_memalign</span></code> on Linux, macOS, and Android) whenever it needs to allocate memory internally. You can instead specify callbacks that Steam Audio will call whenever it needs to allocate or free memory:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="o">*</span> <span class="nf">my_malloc</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">alignment</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// ...</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">my_free</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">block</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// ...</span>
<span class="p">}</span>

<span class="c1">// ...</span>

<span class="c1">// pass pointers to these functions when creating the context</span>
<span class="n">contextSettings</span><span class="p">.</span><span class="n">allocateCallback</span> <span class="o">=</span> <span class="n">my_malloc</span><span class="p">;</span>
<span class="n">contextSettings</span><span class="p">.</span><span class="n">freeCallback</span> <span class="o">=</span> <span class="n">my_free</span><span class="p">;</span>
</pre></div>
</div>
<p>This can be useful if you want to use a custom, optimized memory allocator instead of the OS default. It can also be used to instrument calls to the memory allocator and keep track of how much memory is being used by Steam Audio.</p>
</div>
<div class="section" id="simd-optimizations">
<h3>SIMD Optimizations<a class="headerlink" href="#simd-optimizations" title="Permalink to this headline">¶</a></h3>
<p>Steam Audio uses Single Instruction Multiple Data (SIMD) instructions to optimize various operations. Steam Audio automatically selects the fastest SIMD instruction set to use based on the CPU it’s running on. For example, when running on a CPU that supports Intel Advanced Vector eXtensions (AVX), it will use AVX optimized code. On older processors that do not support AVX, it will fall back to Streaming SIMD Extensions (SSE) instructions.</p>
<p>You can specify which SIMD instruction sets Steam Audio should consider:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// this specifies that Steam Audio should _not_ consider any SIMD instructions newer than AVX2</span>
<span class="n">contextSettings</span><span class="p">.</span><span class="n">simdLevel</span> <span class="o">=</span> <span class="n">IPL_SIMDLEVEL_AVX2</span><span class="p">;</span>
</pre></div>
</div>
<p>Using newer SIMD instruction sets like AVX512 can result in significant performance gains for the computations that use those instructions. However, it may result in increased CPU energy usage, which may in turn lead to the CPU clock frequency being throttled, resulting in a decrease in performance in other tasks that your program might be running.</p>
</div>
<div class="section" id="destroying-steam-audio-api-objects">
<h3>Destroying Steam Audio API objects<a class="headerlink" href="#destroying-steam-audio-api-objects" title="Permalink to this headline">¶</a></h3>
<p>Steam Audio objects may be used from multiple threads. For this reason, they are <em>reference counted</em>. When you create a context, for example, it starts out with a reference count of 1. You can increment this reference count by calling <code class="docutils literal notranslate"><span class="pre">iplContextRetain</span></code>, and decrement the reference count by calling <code class="docutils literal notranslate"><span class="pre">iplContextRelease</span></code>. When the reference count reaches 0, Steam Audio will destroy the context. Every other Steam Audio API object works the same way.</p>
</div>
</div>
<div class="section" id="audio-buffers">
<h2>Audio Buffers<a class="headerlink" href="#audio-buffers" title="Permalink to this headline">¶</a></h2>
<p>Steam Audio processes audio in <em>audio buffers</em>, which contain uncompressed Pulse Code Modulated (PCM) data (just like a <code class="docutils literal notranslate"><span class="pre">.wav</span></code> file).</p>
<p>Audio buffers contain one or more <em>channels</em>; for example, a stereo audio buffer contains 2 channels. Each channel typically contains several <em>samples</em>, which are values of the audio signal’s level at discrete points of time. Each channel has the same number of samples.</p>
<p>The time interval between two successive samples is specified using the <em>sampling rate</em>. Typical sampling rates are 44100 Hz (CD quality) or 48000 Hz.</p>
<p>Steam Audio always uses 32-bit floating-point samples.</p>
<p>Audio buffers are passed to Steam Audio using the <code class="docutils literal notranslate"><span class="pre">IPLAudioBuffer</span></code> structure:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">buffer</span><span class="p">;</span>
<span class="n">buffer</span><span class="p">.</span><span class="n">numChannels</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="n">buffer</span><span class="p">.</span><span class="n">numSamples</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span>
<span class="n">buffer</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">...;</span> <span class="c1">// see below</span>
</pre></div>
</div>
<p>This specifies an audio buffer containing 2 channels, each of which contains 512 samples, for a total of 2 * 512 = 1024 floating point values.</p>
<div class="section" id="interleaved-vs-deinterleaved-audio">
<h3>Interleaved vs. deinterleaved audio<a class="headerlink" href="#interleaved-vs-deinterleaved-audio" title="Permalink to this headline">¶</a></h3>
<p>Most audio file formats, and many audio engines, store audio buffers in an <em>interleaved</em> layout. This means that all the channel values for the first sample are stored contiguously, followed by all the channel values for the second sample, and so on. For example, an interleaved stereo buffer looks like:</p>
<img alt="_images/interleaved.png" src="_images/interleaved.png" />
<p>Steam Audio, on the other hand, stores audio buffers in a <em>deinterleaved</em> layout. This means that all the samples for the first channel are store contiguously, followed by all the samples for the second channel, and so on. A deinterleaved stereo buffer looks like this:</p>
<img alt="_images/deinterleaved.png" src="_images/deinterleaved.png" />
<p>In Steam Audio, the buffers for different channels do not need to be allocated in adjacent memory locations. So to specify the data for an audio buffer, you set the <code class="docutils literal notranslate"><span class="pre">data</span></code> field of the <code class="docutils literal notranslate"><span class="pre">IPLAudioBuffer</span></code> structure to point to an array, each element of which is a pointer to an array containing the samples for a single channel:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">float</span> <span class="n">leftChannel</span><span class="p">[</span><span class="mi">512</span><span class="p">];</span>
<span class="kt">float</span> <span class="n">rightChannel</span><span class="p">[</span><span class="mi">512</span><span class="p">];</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">channels</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">leftChannel</span><span class="p">,</span> <span class="n">rightChannel</span><span class="p">};</span>

<span class="c1">// ...</span>

<span class="n">buffer</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">channels</span><span class="p">;</span>
</pre></div>
</div>
<p>Some audio engines use deinterleaved audio buffers natively, in which case you can just pass pointers to the data provided by the audio engine to Steam Audio via the <code class="docutils literal notranslate"><span class="pre">IPLAudioBuffer</span></code> structure. Otherwise, you can use <code class="docutils literal notranslate"><span class="pre">iplAudioBufferDeinterleave</span></code> and <code class="docutils literal notranslate"><span class="pre">iplAudioBufferInterleave</span></code> to exchange data between interleaved buffers provided by the audio engine, and deinterleaved buffers needed by Steam Audio:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// these are pointers to interleaved data provided by external code</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">inData</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">outData</span><span class="p">;</span>

<span class="c1">// these are temporary buffers allocated by your application</span>
<span class="n">IPLAudioBuffer</span> <span class="n">inBuffer</span><span class="p">;</span>
<span class="n">IPLAudioBuffer</span> <span class="n">outBuffer</span><span class="p">;</span>

<span class="c1">// ...</span>

<span class="c1">// convert from interleaved to deinterleaved</span>
<span class="n">iplAudioBufferDeinterleave</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">inData</span><span class="p">,</span> <span class="n">inBuffer</span><span class="p">);</span>

<span class="c1">// pass inBuffer to some Steam Audio function, which populates outBuffer with some output</span>

<span class="c1">// convert from deinterleaved back to interleaved</span>
<span class="n">iplAudioBufferInterleave</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">outBuffer</span><span class="p">,</span> <span class="n">outData</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="allocating-audio-buffers">
<h3>Allocating audio buffers<a class="headerlink" href="#allocating-audio-buffers" title="Permalink to this headline">¶</a></h3>
<p>If you need to create temporary audio buffers, either for conversion between interleaved and deinterleaved layouts, or because you need to apply a series of effects to an input audio buffer, you can use the <code class="docutils literal notranslate"><span class="pre">iplAudioBufferAllocate</span></code> function:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">tempBuffer</span><span class="p">;</span>
<span class="n">iplAudioBufferAllocate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">tempBuffer</span><span class="p">);</span>
</pre></div>
</div>
<p>The buffer can then be freed using the <code class="docutils literal notranslate"><span class="pre">iplAudioBufferFree</span></code> function.</p>
</div>
</div>
<div class="section" id="hrtf">
<h2>HRTF<a class="headerlink" href="#hrtf" title="Permalink to this headline">¶</a></h2>
<p>The key component of spatial audio is the <em>Head-Related Transfer Function</em> (HRTF). For any direction around the listener, there is an HRTF, which is a pair of filters that specifies how sound arriving from that direction is modified before it reaches the left and right ears of the listener.</p>
<p>The HRTF filters encode the subtle changes to amplitude, arrival time, and spectral content that are caused by the listener’s head, torso, and outer ear. These are the same cues that our brain uses to perceive the spatial origin of sound in the real world.</p>
<p>Since the audio presented to the left and right ears is processed using different filters, this approach is also called <em>binaural</em> rendering. This is also why spatial audio is best experienced over headphones.</p>
<p>Since there are infinite directions around the listener, an HRTF data set typically includes filters for a fixed number of discrete directions only.</p>
<div class="section" id="loading-an-hrtf">
<h3>Loading an HRTF<a class="headerlink" href="#loading-an-hrtf" title="Permalink to this headline">¶</a></h3>
<p>To load an HRTF, create an <code class="docutils literal notranslate"><span class="pre">IPLHRTF</span></code> object. Steam Audio provides a built-in HRTF, which can be loaded easily:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioSettings</span> <span class="n">audioSettings</span><span class="p">{};</span>
<span class="n">audioSettings</span><span class="p">.</span><span class="n">samplingRate</span> <span class="o">=</span> <span class="mi">44100</span><span class="p">;</span>
<span class="n">audioSettings</span><span class="p">.</span><span class="n">frameSize</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">;</span> <span class="c1">// the size of audio buffers we intend to process</span>

<span class="n">IPLHRTFSettings</span> <span class="n">hrtfSettings</span><span class="p">{};</span>
<span class="n">hrtfSettings</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_HRTFTYPE_DEFAULT</span><span class="p">;</span>

<span class="n">IPLHRTF</span> <span class="n">hrtf</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplHRTFCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">audioSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">hrtfSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">hrtf</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-hrtfs">
<span id="ref-guide-sofa"></span><h3>Custom HRTFs<a class="headerlink" href="#custom-hrtfs" title="Permalink to this headline">¶</a></h3>
<p>You can also load a custom HRTF from an external file. This is useful if you want to experiment with other publicly available HRTF data sets, or use a personalized HRTF that is obtained using simulation or measurement.</p>
<p>Custom HRTFs are loaded from SOFA (Spatially Oriented File format for Acoustics) files:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">hrtfSettings</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_HRTFTYPE_SOFA</span><span class="p">;</span>
<span class="n">hrtfSettings</span><span class="p">.</span><span class="n">sofaFileName</span> <span class="o">=</span> <span class="s">&quot;/path/to/hrtf.sofa&quot;</span><span class="p">;</span>
</pre></div>
</div>
<p>Click <a class="reference external" href="https://www.sofaconventions.org">here</a> for more information on this file format.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The SOFA file format allows for very flexible ways of defining HRTFs, but Steam Audio only supports a restricted subset. The following restrictions apply (for more information, including definitions of the terms below, click <a class="reference external" href="https://www.sofaconventions.org">here</a>:</p>
<ul class="simple">
<li><p>SOFA files must use the <code class="docutils literal notranslate"><span class="pre">SimpleFreeFieldHRIR</span></code> convention.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">Data.SamplingRate</span></code> variable may be specified only once, and may contain only a single value. Steam Audio will automatically resample the HRTF data to the user’s output sampling rate at run-time.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">SourcePosition</span></code> variable must be specified once for each measurement.</p></li>
<li><p>Each source must have a single emitter, with <code class="docutils literal notranslate"><span class="pre">EmitterPosition</span></code> set to <code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">0</span> <span class="pre">0]</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">ListenerPosition</span></code> variable may be specified only once (and not once per measurement). Its value must be <code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">0</span> <span class="pre">0]</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">ListenerView</span></code> variable is optional. If specified, its value must be <code class="docutils literal notranslate"><span class="pre">[1</span> <span class="pre">0</span> <span class="pre">0]</span></code> (in Cartesian coordinates) or <code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">0</span> <span class="pre">1]</span></code> (in spherical coordinates).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">ListenerUp</span></code> variable is optional. If specified, its value must be <code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">0</span> <span class="pre">1]</span></code> (in Cartesian coordinates) or <code class="docutils literal notranslate"><span class="pre">[0</span> <span class="pre">90</span> <span class="pre">1]</span></code> (in spherical coordinates).</p></li>
<li><p>The listener must have two receivers. The receiver positions are ignored.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">Data.Delay</span></code> variable may be specified only once. Its value must be 0.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="binaural-effect">
<h2>Binaural Effect<a class="headerlink" href="#binaural-effect" title="Permalink to this headline">¶</a></h2>
<p>To spatialize an audio buffer, you first need to create an <code class="docutils literal notranslate"><span class="pre">IPLBinauralEffect</span></code> object. This object maintains the internal state of a single stream of audio across frames. Typically, you will create one <code class="docutils literal notranslate"><span class="pre">IPLBinauralEffect</span></code> object for each sound source that you want to spatialize:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLBinauralEffectSettings</span> <span class="n">effectSettings</span><span class="p">{};</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">hrtf</span> <span class="o">=</span> <span class="n">hrtf</span><span class="p">;</span>

<span class="n">IPLBinauralEffect</span> <span class="n">effect</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplBinauralEffectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">audioSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effectSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effect</span><span class="p">);</span>
</pre></div>
</div>
<p>Then, to spatialize an audio buffer, call the <code class="docutils literal notranslate"><span class="pre">iplBinauralEffectApply</span></code> function:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">inBuffer</span><span class="p">;</span> <span class="c1">// must be mono or stereo</span>
<span class="n">IPLAudioBuffer</span> <span class="n">outBuffer</span><span class="p">;</span> <span class="c1">// must be stereo</span>

<span class="c1">// ...</span>

<span class="n">IPLBinauralEffectParams</span> <span class="n">params</span><span class="p">{};</span>
<span class="n">params</span><span class="p">.</span><span class="n">direction</span> <span class="o">=</span> <span class="n">IPLVector3</span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">};</span> <span class="c1">// direction from listener to source</span>
<span class="n">params</span><span class="p">.</span><span class="n">hrtf</span> <span class="o">=</span> <span class="n">hrtf</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">interpolation</span> <span class="o">=</span> <span class="n">IPL_HRTFINTERPOLATION_NEAREST</span><span class="p">;</span> <span class="c1">// see below</span>
<span class="n">params</span><span class="p">.</span><span class="n">spatialBlend</span> <span class="o">=</span> <span class="mf">1.0f</span><span class="p">;</span> <span class="c1">// see below</span>

<span class="n">iplBinauralEffectApply</span><span class="p">(</span><span class="n">effect</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">params</span><span class="p">,</span> <span class="n">inBuffer</span><span class="p">,</span> <span class="n">outBuffer</span><span class="p">);</span>
</pre></div>
</div>
<p>The direction from the listener to the source is specified in the listener’s coordinate system.</p>
<p>You can change the HRTF on the fly, which is why you must specify the HRTF both in the <code class="docutils literal notranslate"><span class="pre">IPLBinauralEffectSettings</span></code> and the <code class="docutils literal notranslate"><span class="pre">IPLBinauralEffectParams</span></code> structures.</p>
<div class="section" id="hrtf-interpolation">
<h3>HRTF interpolation<a class="headerlink" href="#hrtf-interpolation" title="Permalink to this headline">¶</a></h3>
<p>When the direction from the listener to the source is <em>not</em> one of the directions for which HRTF filters are available, Steam Audio must estimate the HRTF filter using available data. This is controlled using the <code class="docutils literal notranslate"><span class="pre">interpolation</span></code> field of the <code class="docutils literal notranslate"><span class="pre">IPLBinauralEffectParams</span></code> structure.</p>
<p><em>Nearest-neighbor</em> interpolation (specified by <code class="docutils literal notranslate"><span class="pre">IPL_HRTFINTERPOLATION_NEAREST</span></code>) means selecting the closest direction to the actual source direction for which HRTF data is available. This is the fastest approach. However, for moving sources, you may hear audible transitions as the HRTF switches abruptly from one pair of filters to another. This is most noticeable with wide-band audio, such as white noise, or engine noise.</p>
<p><em>Bilinear</em> interpolation (specified by <code class="docutils literal notranslate"><span class="pre">IPL_HRTFINTERPOLATION_BILINEAR</span></code>) means blending between the 4 closest directions to the actual source direction. This is slower than nearest-neighbor filtering, but results in significantly smoother rendering of moving sources.</p>
</div>
<div class="section" id="spatial-blend">
<h3>Spatial blend<a class="headerlink" href="#spatial-blend" title="Permalink to this headline">¶</a></h3>
<p>You can use Steam Audio to blend between spatialized and unspatialized audio. For example, a radio playing in the distance can be spatialized (or <em>diegetic</em>), but as the listener moves closer, the sound can become less spatialized, until eventually it becomes part of the soundtrack (or <em>non-diegetic</em>).</p>
<p>This is controlled using the <code class="docutils literal notranslate"><span class="pre">spatialBlend</span></code> parameter:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">.</span><span class="n">spatialBlend</span> <span class="o">=</span> <span class="mf">0.25f</span><span class="p">;</span>
</pre></div>
</div>
<p>A value of <code class="docutils literal notranslate"><span class="pre">0.25f</span></code> means that the output of the binaural effect will be a blend of 25% spatialized and 75% unspatialized audio.</p>
</div>
</div>
<div class="section" id="ambisonics">
<h2>Ambisonics<a class="headerlink" href="#ambisonics" title="Permalink to this headline">¶</a></h2>
<p>Ambisonics is a surround sound format that is especially well-suited to spatial audio applications. Ambisonic audio differs from traditional surround sound formats (5.1, 7.1, etc.) in a few important ways.</p>
<p>Ambisonic audio can describe sound reaching the listener from a full sphere of directions, including sounds that are vertically above or below the listener. On the other hand, traditional surround sound formats can only describe sounds in a horizontal plane around the listener.</p>
<p>Traditional surround sound formats represent the directional variation of sound using discrete channels, each of which is intended to be played back from a specific speaker. For example, a 5.1 surround sound system includes front-left, front-right, center, rear-left, and rear-right speakers. A sound source that is between the front-left and center speakers is then approximated by panning the audio signal between those two speakers.</p>
<p>In contrast, Ambisonic audio expresses any directional variation as a weighted sum of <em>basis functions</em> defined over the sphere of directions around the listener. (This is analogous to how the Fourier transform represents any time-varying function as a weighted sum of sinusoids.) For more information, click <a class="reference external" href="https://en.wikipedia.org/wiki/Ambisonics">here</a>.</p>
<p>Ambisonic audio has an <em>order</em>, which essentially defines the number of channels. Ambisonic order N requires (N + 1)^2 channels. Order 0 has 1 channel, order 1 has 4 channels, order 2 has 9 channels, and so on. The higher the order, the more precisely a given directional variation can be represented.</p>
<p>You can use Ambisonic audio to represent <em>sound fields</em>. These are sounds that arrive from a variety of directions around the listener, all represented in a single audio clip. These are often useful for ambient sounds, or spatialized music.</p>
<p>Another common use for Ambisonics is as an intermediate mixing format. Point sources and sound fields can both be represented, processed and mixed in Ambisonic format. Once the final mix is obtained, it can be spatialized and rendered over the user’s speakers or headphones.</p>
<div class="section" id="encoding-a-point-source-to-ambisonics">
<h3>Encoding a point source to Ambisonics<a class="headerlink" href="#encoding-a-point-source-to-ambisonics" title="Permalink to this headline">¶</a></h3>
<p>Given an audio signal being emitted by a point source, you can encode it into an Ambisonic sound field arriving at the listener using an <code class="docutils literal notranslate"><span class="pre">IPLAmbisonicsEncodeEffect</span></code> object. To create an Ambisonics encode effect, specify the Ambisonic order you want to encode to:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAmbisonicsEncodeEffectSettings</span> <span class="n">effectSettings</span><span class="p">{};</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">maxOrder</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="c1">// 2nd order Ambisonics (9 channels)</span>

<span class="n">IPLAmbisonicsEncodeEffect</span> <span class="n">effect</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplAmbisonicsEncodeEffectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">audioSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effectSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effect</span><span class="p">);</span>
</pre></div>
</div>
<p>You can then use <code class="docutils literal notranslate"><span class="pre">iplAmbisonicsEncodeEffectApply</span></code> to encode an audio buffer:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">inBuffer</span><span class="p">;</span> <span class="c1">// must be mono</span>
<span class="n">IPLAudioBuffer</span> <span class="n">outBuffer</span><span class="p">;</span> <span class="c1">// must have 9 channels in this example</span>

<span class="c1">// ...</span>

<span class="n">IPLAmbisonicsEncodeEffectParams</span> <span class="n">params</span><span class="p">{};</span>
<span class="n">params</span><span class="p">.</span><span class="n">direction</span> <span class="o">=</span> <span class="n">IPLVector3</span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">};</span>
<span class="n">params</span><span class="p">.</span><span class="n">order</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="n">iplAmbisonicsEncodeEffectApply</span><span class="p">(</span><span class="n">effect</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">params</span><span class="p">,</span> <span class="n">inBuffer</span><span class="p">,</span> <span class="n">outBuffer</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="decoding-ambisonics-for-rendering">
<h3>Decoding Ambisonics for rendering<a class="headerlink" href="#decoding-ambisonics-for-rendering" title="Permalink to this headline">¶</a></h3>
<p>To decode Ambisonics and render it to a multichannel audio buffer, use an <code class="docutils literal notranslate"><span class="pre">IPLAmbisonicsDecodeEffect</span></code>. To create one, use the <code class="docutils literal notranslate"><span class="pre">iplAmbisonicsDecodeEffectCreate</span></code> function:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAmbisonicsDecodeEffectSettings</span> <span class="n">effectSettings</span><span class="p">{};</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">maxOrder</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">hrtf</span> <span class="o">=</span> <span class="n">hrtf</span><span class="p">;</span>

<span class="n">IPLAmbisonicsDecodeEffect</span> <span class="n">effect</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplAmbisonicsDecodeEffectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">audioSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effectSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effect</span><span class="p">);</span>
</pre></div>
</div>
<p>You can then use <code class="docutils literal notranslate"><span class="pre">iplAmbisonicsDecodeEffectApply</span></code> to decode an audio buffer:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">inBuffer</span><span class="p">;</span> <span class="c1">// must have 9 channels in this example</span>
<span class="n">IPLAudioBuffer</span> <span class="n">outBuffer</span><span class="p">;</span> <span class="c1">// must be stereo</span>

<span class="n">IPLCoordinateSpace3</span> <span class="n">listenerCoordinates</span><span class="p">;</span> <span class="c1">// the listener&#39;s coordinate system</span>

<span class="c1">// ...</span>

<span class="n">IPLAmbisonicsDecodeEffectParams</span> <span class="n">params</span><span class="p">{};</span>
<span class="n">params</span><span class="p">.</span><span class="n">order</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">hrtf</span> <span class="o">=</span> <span class="n">hrtf</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">orientation</span> <span class="o">=</span> <span class="n">listenerCoordinates</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">binaural</span> <span class="o">=</span> <span class="n">IPL_TRUE</span><span class="p">;</span>

<span class="n">iplAmbisonicsDecodeEffectApply</span><span class="p">(</span><span class="n">effect</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">params</span><span class="p">,</span> <span class="n">inBuffer</span><span class="p">,</span> <span class="n">outBuffer</span><span class="p">);</span>
</pre></div>
</div>
<p>This decodes a 2nd order Ambisonic audio buffer, spatializes it using the HRTF, and stores the result in a stereo audio buffer.</p>
<p>You can instead decode to a multichannel surround sound format as follows. First, when creating the effect, specify the speaker layout you want to decode to:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">effectSettings</span><span class="p">.</span><span class="n">speakerLayout</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_SPEAKERLAYOUTTYPE_SURROUND_7_1</span><span class="p">;</span>
</pre></div>
</div>
<p>Then, when applying the effect, disable binaural rendering:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">.</span><span class="n">binaural</span> <span class="o">=</span> <span class="n">IPL_FALSE</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="section" id="rotating-ambisonic-sound-fields">
<h3>Rotating Ambisonic sound fields<a class="headerlink" href="#rotating-ambisonic-sound-fields" title="Permalink to this headline">¶</a></h3>
<p>One of the key advantages of Ambisonic audio is that Ambisonic sound fields can be efficiently rotated around the listener. Steam Audio does this using the <code class="docutils literal notranslate"><span class="pre">orientation</span></code> field of the <code class="docutils literal notranslate"><span class="pre">IPLAmbisonicsDecodeEffectParams</span></code> structure. This field stores the orientation of the listener <em>relative to the sound field</em>.</p>
<p>If you want the sound field to remain fixed in world space as the listener looks around, pass in the world space direction vectors of the listener’s coordinate system.</p>
<p>If you want the sound field to remain fixed around the listener’s head, pass in the coordinate axes:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">IPLVector3</span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">};</span>
<span class="n">params</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">IPLVector3</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">};</span>
<span class="n">params</span><span class="p">.</span><span class="n">orientation</span><span class="p">.</span><span class="n">ahead</span> <span class="o">=</span> <span class="n">IPLVector3</span><span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">,</span> <span class="mf">-1.0f</span><span class="p">};</span>
</pre></div>
</div>
<p>Other effects, such as a sound field that slowly swirls around the listener’s head, can be obtained by animating the <code class="docutils literal notranslate"><span class="pre">orientation</span></code> field over multiple audio frames.</p>
</div>
</div>
<div class="section" id="direct-effect">
<h2>Direct Effect<a class="headerlink" href="#direct-effect" title="Permalink to this headline">¶</a></h2>
<p>Sound propagating along the direct (straight line) path from the source to the listener can be affected by many things. It can attenuate over distance. It can be affected by the source’s <em>directivity pattern</em>, which describes how the source emits sound in different directions. It can also be occluded by geometry.</p>
<p>Steam Audio renders all of these effects using an <code class="docutils literal notranslate"><span class="pre">IPLDirectEffect</span></code> object:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLDirectEffectSettings</span> <span class="n">effectSettings</span><span class="p">{};</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">numChannels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// input and output buffers will have 1 channel</span>

<span class="n">IPLDirectEffect</span> <span class="n">effect</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplDirectEffectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">audioSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effectSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effect</span><span class="p">);</span>
</pre></div>
</div>
<p>To apply the direct effect:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">inBuffer</span><span class="p">;</span> <span class="c1">// must be mono in this example</span>
<span class="n">IPLAudioBuffer</span> <span class="n">outBuffer</span><span class="p">;</span> <span class="c1">// must be mono in this example</span>

<span class="n">IPLDirectEffectParams</span> <span class="n">params</span><span class="p">{};</span>
<span class="n">params</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="p">...;</span> <span class="c1">// see below</span>

<span class="n">iplDirectEffectApply</span><span class="p">(</span><span class="n">effect</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">params</span><span class="p">,</span> <span class="n">inBuffer</span><span class="p">,</span> <span class="n">outBuffer</span><span class="p">);</span>
</pre></div>
</div>
<p>A direct effect can combine the effects of distance attenuation, directivity, occlusion, and more. Below are some common examples.</p>
<div class="section" id="distance-attenuation">
<h3>Distance attenuation<a class="headerlink" href="#distance-attenuation" title="Permalink to this headline">¶</a></h3>
<p>The attenuation of sound over distance can be modeled as follows:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_DIRECTEFFECTFLAGS_DISTANCEATTENUATION</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">distanceAttenuation</span> <span class="o">=</span> <span class="mf">0.6f</span><span class="p">;</span>
</pre></div>
</div>
<p>This enables the rendering of distance attenuation, and causes the output to be rendered at 60% of the volume of the input. Typically, the value of the <code class="docutils literal notranslate"><span class="pre">distanceAttenuation</span></code> field will be determined based on the actual distance between the source and the listener.</p>
<p>Steam Audio provides a flexible way of specifying distance attenuation models using the <code class="docutils literal notranslate"><span class="pre">IPLDistanceAttenuationModel</span></code> structure:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLDistanceAttenuationModel</span> <span class="n">distanceAttenuationModel</span><span class="p">{};</span>
<span class="n">distanceAttenuationModel</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_DISTANCEATTENUATIONTYPE_DEFAULT</span><span class="p">;</span>
</pre></div>
</div>
<p>This specifies Steam Audio’s default attenuation model. You can also tweak the default attenuation model, or specify any arbitrary model of your own.</p>
<p>You can then use the <code class="docutils literal notranslate"><span class="pre">iplDistanceAttenuationCalculate</span></code> function to calculate distance attenuation for a specific source and listener:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLVector3</span> <span class="n">sourcePosition</span><span class="p">;</span> <span class="c1">// the world-space position of the source</span>
<span class="n">IPLVector3</span> <span class="n">listenerPosition</span><span class="p">;</span> <span class="c1">// the world-space position of the listener</span>

<span class="kt">float</span> <span class="n">distanceAttenuation</span> <span class="o">=</span> <span class="n">iplDistanceAttenuationCalculate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">sourcePosition</span><span class="p">,</span> <span class="n">listenerPosition</span><span class="p">,</span> <span class="n">distanceAttenuationModel</span><span class="p">);</span>

<span class="n">params</span><span class="p">.</span><span class="n">distanceAttenuation</span> <span class="o">=</span> <span class="n">distanceAttenuation</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="section" id="air-absorption">
<h3>Air absorption<a class="headerlink" href="#air-absorption" title="Permalink to this headline">¶</a></h3>
<p>Different frequencies of sound can attenuate differently over distance. For example, distant explosions sound muffled because higher frequencies attenuate faster than lower frequencies. Steam Audio models this phenomenon as <em>air absorption</em>. This involves providing the direct effect with 3-band EQ values describing the sound after attenuation:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_DIRECTEFFECTFLAGS_AIRABSORPTION</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">airAbsorption</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9f</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">airAbsorption</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.7f</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">airAbsorption</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5f</span><span class="p">;</span>
</pre></div>
</div>
<p>Typically, the air absorption EQ values will be determined based on the actual distance between the source and the listener.</p>
<p>Steam Audio provides a flexible way of specifying air absorption models using the <code class="docutils literal notranslate"><span class="pre">IPLAirAbsorptionModel</span></code> structure:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAirAbsorptionModel</span> <span class="n">airAbsorptionModel</span><span class="p">{};</span>
<span class="n">airAbsorptionModel</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_AIRABSORPTIONTYPE_DEFAULT</span><span class="p">;</span>
</pre></div>
</div>
<p>This specifies Steam Audio’s default air absorption model. You can also tweak the default air absorption model, or specify any arbitrary model of your own.</p>
<p>You can then use the <code class="docutils literal notranslate"><span class="pre">iplAirAbsorptionCalculate</span></code> function to calculate air absorption for a specific source and listener:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLVector3</span> <span class="n">sourcePosition</span><span class="p">;</span> <span class="c1">// the world-space position of the source</span>
<span class="n">IPLVector3</span> <span class="n">listenerPosition</span><span class="p">;</span> <span class="c1">// the world-space position of the listener</span>

<span class="n">iplAirAbsorptionCalculate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">sourcePosition</span><span class="p">,</span> <span class="n">listenerPosition</span><span class="p">,</span> <span class="n">airAbsorptionModel</span><span class="p">,</span> <span class="n">params</span><span class="p">.</span><span class="n">airAbsorption</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="directivity">
<h3>Directivity<a class="headerlink" href="#directivity" title="Permalink to this headline">¶</a></h3>
<p>Sound sources can emit sound with different intensities in different directions. For example, a megaphone mostly projects sound towards the front. Steam Audio models this using a <em>directivity pattern</em>. Due to a source’s directivity pattern, and its orientation and position relative to the listener, a further attenuation is applied to it, on top of any distance attenuation or air absorption:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_DIRECTEFFECTFLAGS_DIRECTIVITY</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">directivity</span> <span class="o">=</span> <span class="mf">0.7f</span><span class="p">;</span>
</pre></div>
</div>
<p>Typically, the directivity value will be determined based on the actual position and orientation of the source.</p>
<p>Steam Audio provides a flexible way of specifying directivity patterns using the <code class="docutils literal notranslate"><span class="pre">IPLDirectivity</span></code> structure:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLDirectivity</span> <span class="n">directivity</span><span class="p">{};</span>
<span class="n">directivity</span><span class="p">.</span><span class="n">dipoleWeight</span> <span class="o">=</span> <span class="mf">0.5f</span><span class="p">;</span>
<span class="n">directivity</span><span class="p">.</span><span class="n">dipolePower</span> <span class="o">=</span> <span class="mf">2.0f</span><span class="p">;</span>
</pre></div>
</div>
<p>Steam Audio’s default directivity pattern is a weighted dipole. The <code class="docutils literal notranslate"><span class="pre">dipoleWeight</span></code> field specifies a blend between a monopole (a source that emits sound equally in all directions) and a dipole (a source that emits sound mostly to the front and the back). In this example, a <code class="docutils literal notranslate"><span class="pre">dipoleWeight</span></code> value of <code class="docutils literal notranslate"><span class="pre">0.5f</span></code> results in a 50% monopole and 50% dipole blend. This is also called a <em>cardioid</em> directivity pattern.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">dipolePower</span></code> field controls the sharpness of the dipole pattern. Higher values result in more focused sound.</p>
<p>You can also specify any arbitrary directivity pattern of your own.</p>
<p>You can then use the <code class="docutils literal notranslate"><span class="pre">iplDirectivityCalculate</span></code> function to calculate directivity for a specific source and listener:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLCoordinateSpace3</span> <span class="n">sourceCoordinates</span><span class="p">;</span> <span class="c1">// the world-space position and orientation of the source</span>
<span class="n">IPLVector3</span> <span class="n">listenerPosition</span><span class="p">;</span> <span class="c1">// the world-space position of the listener</span>

<span class="n">params</span><span class="p">.</span><span class="n">directivity</span> <span class="o">=</span> <span class="n">iplDirectivityCalculate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">sourceCoordinates</span><span class="p">,</span> <span class="n">listenerPosition</span><span class="p">,</span> <span class="n">directivity</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="occlusion-and-transmission">
<h3>Occlusion and transmission<a class="headerlink" href="#occlusion-and-transmission" title="Permalink to this headline">¶</a></h3>
<p>Geometry, like a wall, can completely or partially occlude the direct sound path from a source to the listener. Here, partial occlusion means that some portion of the source is visible to the listener.</p>
<p>In addition, some portion of the occluded sound may be transmitted through the occluding geometry. This transmitted sound is affected by the material properties of the occluding geometry.</p>
<p>Steam Audio models occlusion as a fraction value between 0 and 1, where 0 means fully occluded and 1 means not occluded at all. Transmission is modeled as 3-band EQ values. The EQ values are only applied to the portion of sound that is occluded:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">params</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_DIRECTEFFECTFLAGS_OCCLUSION</span> <span class="o">|</span> <span class="n">IPL_DIRECTEFFECTFLAGS_TRANSMISSION</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">occlusion</span> <span class="o">=</span> <span class="mf">0.4f</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">transmission</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3f</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">transmission</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.2f</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">transmission</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.1f</span><span class="p">;</span>
</pre></div>
</div>
<p>This describes a configuration where 40% of the source’s sound is occluded, and an EQ is applied to this occluded portion of the sound.</p>
<p>Typically, the occlusion and transmission values will be determined by tracing rays through the scene to find occluding geometry.</p>
</div>
</div>
<div class="section" id="scene">
<h2>Scene<a class="headerlink" href="#scene" title="Permalink to this headline">¶</a></h2>
<p>Any geometry that might interact with sound should be contained in an <code class="docutils literal notranslate"><span class="pre">IPLScene</span></code> object:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSceneSettings</span> <span class="n">sceneSettings</span><span class="p">{};</span>
<span class="n">sceneSettings</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_SCENETYPE_DEFAULT</span><span class="p">;</span>

<span class="n">IPLScene</span> <span class="n">scene</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplSceneCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sceneSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">scene</span><span class="p">);</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">IPLScene</span></code> itself doesn’t contain any geometry. Instead you create one or more <code class="docutils literal notranslate"><span class="pre">IPLStaticMesh</span></code> or <code class="docutils literal notranslate"><span class="pre">IPLInstancedMesh</span></code> objects that contain the actual geometry, then add them to the scene.</p>
<div class="section" id="static-geometry">
<h3>Static geometry<a class="headerlink" href="#static-geometry" title="Permalink to this headline">¶</a></h3>
<p>Geometry that will not move or deform in any way should be specified using <code class="docutils literal notranslate"><span class="pre">IPLStaticMesh</span></code> objects:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// four vertices of a unit square in the x-y plane</span>
<span class="n">IPLVector3</span> <span class="n">vertices</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">},</span>
    <span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">},</span>
    <span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">},</span>
    <span class="p">{</span><span class="mf">0.0f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">,</span> <span class="mf">0.0f</span><span class="p">}</span>
<span class="p">};</span>

<span class="c1">// triangle indices use counter-clockwise winding order</span>
<span class="n">IPLTriangle</span> <span class="n">triangles</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">{</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">},</span>
    <span class="p">{</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">};</span>

<span class="n">IPLMaterial</span> <span class="n">materials</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">{</span> <span class="p">{</span><span class="mf">0.1f</span><span class="p">,</span> <span class="mf">0.1f</span><span class="p">,</span> <span class="mf">0.1f</span><span class="p">},</span> <span class="mf">0.5f</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.2f</span><span class="p">,</span> <span class="mf">0.2f</span><span class="p">,</span> <span class="mf">0.2f</span><span class="p">}</span> <span class="p">}</span>
<span class="p">};</span>

<span class="c1">// both triangles use the same material</span>
<span class="n">IPLint32</span> <span class="n">materialIndices</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">};</span>

<span class="n">IPLStaticMeshSettings</span> <span class="n">staticMeshSettings</span><span class="p">{};</span>
<span class="n">staticMeshSettings</span><span class="p">.</span><span class="n">numVertices</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
<span class="n">staticMeshSettings</span><span class="p">.</span><span class="n">numTriangles</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="n">staticMeshSettings</span><span class="p">.</span><span class="n">numMaterials</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">staticMeshSettings</span><span class="p">.</span><span class="n">vertices</span> <span class="o">=</span> <span class="n">vertices</span><span class="p">;</span>
<span class="n">staticMeshSettings</span><span class="p">.</span><span class="n">triangles</span> <span class="o">=</span> <span class="n">triangles</span><span class="p">;</span>
<span class="n">staticMeshSettings</span><span class="p">.</span><span class="n">materialIndices</span> <span class="o">=</span> <span class="n">materialIndices</span><span class="p">;</span>
<span class="n">staticMeshSettings</span><span class="p">.</span><span class="n">materials</span> <span class="o">=</span> <span class="n">materials</span><span class="p">;</span>

<span class="n">IPLStaticMesh</span> <span class="n">staticMesh</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplStaticMeshCreate</span><span class="p">(</span><span class="n">scene</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">staticMeshSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">staticMesh</span><span class="p">);</span>
</pre></div>
</div>
<p>Triangles are defined as <em>indices</em> into the <code class="docutils literal notranslate"><span class="pre">vertices</span></code> array. The indices should be provided in counter-clockwise order, meaning if the triangle is viewed with its front side facing the viewer, then the vertices appear in counter-clockwise order.</p>
<p>Once the static mesh is created, the <code class="docutils literal notranslate"><span class="pre">vertices</span></code>, <code class="docutils literal notranslate"><span class="pre">triangles</span></code>, <code class="docutils literal notranslate"><span class="pre">materialIndices</span></code>, and <code class="docutils literal notranslate"><span class="pre">materials</span></code> arrays can be freed if needed.</p>
<p>You can add a static mesh to a scene (using <code class="docutils literal notranslate"><span class="pre">iplStaticMeshAdd</span></code>) or remove it (using <code class="docutils literal notranslate"><span class="pre">iplStaticMeshRemove</span></code>) on the fly. You must call <code class="docutils literal notranslate"><span class="pre">iplSceneCommit</span></code> for the changes to take effect:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplStaticMeshAdd</span><span class="p">(</span><span class="n">staticMesh</span><span class="p">,</span> <span class="n">scene</span><span class="p">);</span>
<span class="n">iplSceneCommit</span><span class="p">(</span><span class="n">scene</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="dynamic-geometry">
<h3>Dynamic geometry<a class="headerlink" href="#dynamic-geometry" title="Permalink to this headline">¶</a></h3>
<p>Geometry that might move should be specified using <code class="docutils literal notranslate"><span class="pre">IPLInstancedMesh</span></code> objects. Instanced meshes cannot deform in any way; they can only undergo rigid-body motion.</p>
<p>As the name suggests, instanced meshes are defined as instances of some <code class="docutils literal notranslate"><span class="pre">IPLScene</span></code> (called the <em>sub-scene</em>) which can be placed inside another scene with a specified 4x4 affine transform matrix applied:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// this should contain at least 1 static mesh</span>
<span class="n">IPLScene</span> <span class="n">subScene</span><span class="p">;</span>

<span class="c1">// this should be a transform that maps from the subScene&#39;s local coordinates</span>
<span class="c1">// to the scene&#39;s global (world-space) coordinates</span>
<span class="n">IPLMatrix4x4</span> <span class="n">transform</span><span class="p">;</span>

<span class="n">IPLInstancedMeshSettings</span> <span class="n">instancedMeshSettings</span><span class="p">{};</span>
<span class="n">instancedMeshSettings</span><span class="p">.</span><span class="n">subScene</span> <span class="o">=</span> <span class="n">subScene</span><span class="p">;</span>
<span class="n">instancedMeshSettings</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span><span class="p">;</span>

<span class="n">IPLInstancedMesh</span> <span class="n">instancedMesh</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplInstancedMeshCreate</span><span class="p">(</span><span class="n">scene</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">instancedMeshSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">instancedMesh</span><span class="p">);</span>
</pre></div>
</div>
<p>As with static meshes, you can add an instanced mesh to a scene (using <code class="docutils literal notranslate"><span class="pre">iplInstancedMeshAdd</span></code>) or remove it (using <code class="docutils literal notranslate"><span class="pre">iplInstancedMeshRemove</span></code>) on the fly. You can also modify the transform over time, using <code class="docutils literal notranslate"><span class="pre">iplInstancedMeshUpdateTransform</span></code>. You must call <code class="docutils literal notranslate"><span class="pre">iplSceneCommit</span></code> for the changes to take effect:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// some new transform that results in the instanced mesh moving in world space</span>
<span class="n">IPLMatrix4x4</span> <span class="n">newTransform</span><span class="p">;</span>

<span class="n">iplInstancedMeshUpdateTransform</span><span class="p">(</span><span class="n">instancedMesh</span><span class="p">,</span> <span class="n">scene</span><span class="p">,</span> <span class="n">newTransform</span><span class="p">);</span>
<span class="n">iplSceneCommit</span><span class="p">(</span><span class="n">scene</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="serializing-scenes">
<h3>Serializing scenes<a class="headerlink" href="#serializing-scenes" title="Permalink to this headline">¶</a></h3>
<p>Some game engines may not provide a means for accessing geometry at run-time. In such cases, you can export static meshes to disk for Steam Audio to load them later.</p>
<p>To serialize a static mesh to disk, start by creating an empty <code class="docutils literal notranslate"><span class="pre">IPLSerializedObject</span></code>:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSerializedObjectSettings</span> <span class="n">soSettings</span><span class="p">{};</span>

<span class="n">IPLSerializedObject</span> <span class="n">serializedObject</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplSerializedObjectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">soSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">serializedObject</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, use <code class="docutils literal notranslate"><span class="pre">iplStaticMeshSave</span></code> to serialize the static mesh to an in-memory buffer:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplStaticMeshSave</span><span class="p">(</span><span class="n">staticMesh</span><span class="p">,</span> <span class="n">serializedObject</span><span class="p">);</span>
</pre></div>
</div>
<p>The serialized object now contains an array of bytes containing a representation of the static mesh that can be saved to disk:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLsize</span> <span class="n">size</span> <span class="o">=</span> <span class="n">iplSerializedObjectGetSize</span><span class="p">(</span><span class="n">serializedObject</span><span class="p">);</span>
<span class="n">IPLbyte</span><span class="o">*</span> <span class="n">buffer</span> <span class="o">=</span> <span class="n">iplSerializedObjectGetData</span><span class="p">(</span><span class="n">serializedObject</span><span class="p">);</span>

<span class="c1">// you can now write &#39;size&#39; bytes starting at the address &#39;buffer&#39; to disk</span>
</pre></div>
</div>
<p>To load the static mesh, you first read from the file on disk into a serialized object, then create the static mesh from the serialized object:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLsize</span> <span class="n">size</span><span class="p">;</span> <span class="c1">// size in bytes of the file</span>
<span class="n">IPLbyte</span><span class="o">*</span> <span class="n">buffer</span><span class="p">;</span> <span class="c1">// buffer containing the entire file</span>

<span class="n">IPLSerializedObjectSettings</span> <span class="n">soSettings</span><span class="p">{};</span>
<span class="n">soSettings</span><span class="p">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span><span class="p">;</span>
<span class="n">soSettings</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">;</span>

<span class="n">IPLSerializedObject</span> <span class="n">serializedObject</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplSerializedObjectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">soSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">serializedObject</span><span class="p">);</span>

<span class="n">IPLStaticMesh</span> <span class="n">staticMesh</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplStaticMeshLoad</span><span class="p">(</span><span class="n">scene</span><span class="p">,</span> <span class="n">serializedObject</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">staticMesh</span><span class="p">);</span>

<span class="c1">// you can now free the memory in &#39;buffer&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="using-your-own-ray-tracer">
<h3>Using your own ray tracer<a class="headerlink" href="#using-your-own-ray-tracer" title="Permalink to this headline">¶</a></h3>
<p>Steam Audio provides multiple ray tracing implementations with different trade-offs:</p>
<ul class="simple">
<li><p>Steam Audio’s built-in ray tracer, which works on all platforms.</p></li>
<li><p>Intel’s Embree ray tracer, which works on Windows, Linux, and macOS, and is faster than the built-in ray tracer.</p></li>
<li><p>AMD’s Radeon Rays ray tracer, which works on 64-bit Windows and requires a GPU that supports OpenCL 1.2 or later. It is significantly faster than the built-in ray tracer or Embree, but requires care to ensure that it doesn’t take up too much GPU processing time from graphical rendering or other GPU workloads.</p></li>
</ul>
<p>You can also provide callbacks to your own ray tracing implementation. This way, you can reuse your existing ray tracing infrastructure, which may be better optimized for your specific application. For more details, see <a class="reference internal" href="scene.html#ref-scene"><span class="std std-ref">Scene</span></a>.</p>
</div>
</div>
<div class="section" id="simulation">
<h2>Simulation<a class="headerlink" href="#simulation" title="Permalink to this headline">¶</a></h2>
<p>To simulate occlusion, transmission, reflections, reverb, or pathing, you must first create an <code class="docutils literal notranslate"><span class="pre">IPLSimulator</span></code> object. Typically, a simulator is created once at app startup, and persists throughout the lifetime of the application:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationSettings</span> <span class="n">simulationSettings</span><span class="p">{};</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_DIRECT</span><span class="p">;</span> <span class="c1">// this enables occlusion/transmission simulation</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">sceneType</span> <span class="o">=</span> <span class="n">IPL_SCENETYPE_DEFAULT</span><span class="p">;</span>
<span class="c1">// see below for examples of how to initialize the remaining fields of this structure</span>

<span class="n">IPLSimulator</span> <span class="n">simulator</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplSimulatorCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">simulationSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">simulator</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, specify the scene within which you want to run simulations. This determines the geometry against which rays will be traced:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplSimulatorSetScene</span><span class="p">(</span><span class="n">simulator</span><span class="p">,</span> <span class="n">scene</span><span class="p">);</span>
<span class="n">iplSimulatorCommit</span><span class="p">(</span><span class="n">simulator</span><span class="p">);</span>
</pre></div>
</div>
<p>You must call <code class="docutils literal notranslate"><span class="pre">iplSimulatorCommit</span></code> after calling <code class="docutils literal notranslate"><span class="pre">iplSimulatorSetScene</span></code> for the changes to take effect.</p>
<div class="section" id="sources">
<h3>Sources<a class="headerlink" href="#sources" title="Permalink to this headline">¶</a></h3>
<p>For each sound source for which you want to run simulations, you must create an <code class="docutils literal notranslate"><span class="pre">IPLSource</span></code> object. These objects typically persist throughout the lifetime of the in-game object they are associated with:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplSourceSettings</span> <span class="n">sourceSettings</span><span class="p">{};</span>
<span class="n">sourceSettings</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_DIRECT</span><span class="p">;</span> <span class="c1">// this enables occlusion/transmission simulator for this source</span>

<span class="n">IPLSource</span> <span class="n">source</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplSourceCreate</span><span class="p">(</span><span class="n">simulator</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sourceSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">source</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, add it to the simulator so as to include it in any future simulations:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplSourceAdd</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">simulator</span><span class="p">);</span>
<span class="n">iplSimulatorCommit</span><span class="p">(</span><span class="n">simulator</span><span class="p">);</span>
</pre></div>
</div>
<p>You can call <code class="docutils literal notranslate"><span class="pre">iplSourceRemove</span></code> to prevent a source from being included in any future simulations. Again, you must call <code class="docutils literal notranslate"><span class="pre">iplSimulatorCommit</span></code> after calling <code class="docutils literal notranslate"><span class="pre">iplSourceAdd</span></code> or <code class="docutils literal notranslate"><span class="pre">iplSourceRemove</span></code> for the changes to take effect.</p>
</div>
<div class="section" id="simulating-occlusion-and-transmission">
<h3>Simulating occlusion and transmission<a class="headerlink" href="#simulating-occlusion-and-transmission" title="Permalink to this headline">¶</a></h3>
<p>Now that we have created a simulator, created a source, and added the source to the simulator, we can simulate occlusion and transmission for the source. First, we specify values for various properties of the source:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLCoordinateSpace3</span> <span class="n">sourceCoordinates</span><span class="p">;</span> <span class="c1">// the world-space position and orientation of the source</span>

<span class="n">IPLSimulationInputs</span> <span class="n">inputs</span><span class="p">{};</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_DIRECT</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">directFlags</span> <span class="o">=</span> <span class="n">IPL_DIRECTSIMULATIONFLAGS_OCCLUSION</span> <span class="o">|</span> <span class="n">IPL_DIRECTSIMULATIONFLAGS_TRANSMISSION</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">sourceCoordinates</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">occlusionType</span> <span class="o">=</span> <span class="n">IPL_OCCLUSIONTYPE_RAYCAST</span><span class="p">;</span>

<span class="n">iplSourceSetInputs</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_DIRECT</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">inputs</span><span class="p">);</span>
</pre></div>
</div>
<p>This causes occlusion and transmission to be simulated the next time the simulator is run (see below). It also specifies that occlusion should be simulated by tracing a single ray from the source to the listener. This is an efficient occlusion algorithm, but may result in sudden transitions in and out of occlusion. There are other parameters you can configure to enable smoother transitions, at the cost of increased CPU usage. See <a class="reference internal" href="simulation.html#ref-simulation"><span class="std std-ref">Simulation</span></a> for more details.</p>
<p>Next, we specify values for various global properties of the simulation:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLCoordinateSpace3</span> <span class="n">listenerCoordinates</span><span class="p">;</span> <span class="c1">// the world-space position and orientation of the listener</span>

<span class="n">IPLSimulationSharedInputs</span> <span class="n">sharedInputs</span><span class="p">{};</span>
<span class="n">sharedInputs</span><span class="p">.</span><span class="n">listener</span> <span class="o">=</span> <span class="n">listenerCoordinates</span><span class="p">;</span>

<span class="n">iplSimulatorSetSharedInputs</span><span class="p">(</span><span class="n">simulator</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_DIRECT</span><span class="p">,</span> <span class="n">sharedInputs</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, we run the simulation:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplSimulatorRunDirect</span><span class="p">(</span><span class="n">simulator</span><span class="p">);</span>
</pre></div>
</div>
<p>This is a blocking call that runs occlusion and transmission simulations for all sources that have been added to the simulator. You may choose to run this in your game’s main update thread, or from a separate thread, depending on CPU usage.</p>
<p>Finally, we retrieve the simulation results:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationOutputs</span> <span class="n">outputs</span><span class="p">{};</span>
<span class="n">iplSourceGetOutputs</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_DIRECT</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">outputs</span><span class="p">);</span>

<span class="n">IPLDirectEffectParams</span> <span class="n">params</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">direct</span><span class="p">;</span> <span class="c1">// this can be passed to a direct effect</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="reflections">
<h2>Reflections<a class="headerlink" href="#reflections" title="Permalink to this headline">¶</a></h2>
<p>Steam Audio can simulate how sound from a source is reflected off of surrounding geometry. This can lead to better spatialization and increased immersion, but comes at a significant CPU usage cost. For this reason, Steam Audio provides many options for controlling how and when reflections are simulated, so you can find the right trade-off between simulation quality and performance for your application.</p>
<p>In this section, we will describe the basic steps required to enable real-time reflection simulation, without focusing too much on performance.</p>
<div class="section" id="initializing-a-simulator-for-reflections">
<h3>Initializing a simulator for reflections<a class="headerlink" href="#initializing-a-simulator-for-reflections" title="Permalink to this headline">¶</a></h3>
<p>First, when creating the simulator, you must specify parameters related to reflection simulation:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationSettings</span> <span class="n">simulationSettings</span><span class="p">{};</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_REFLECTIONS</span><span class="p">;</span> <span class="c1">// this enables reflection simulation</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">sceneType</span> <span class="o">=</span> <span class="n">IPL_SCENETYPE_DEFAULT</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">reflectionType</span> <span class="o">=</span> <span class="n">IPL_REFLECTIONEFFECTTYPE_CONVOLUTION</span><span class="p">;</span> <span class="c1">// see below</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">maxNumRays</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">numDiffuseSamples</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">maxDuration</span> <span class="o">=</span> <span class="mf">2.0f</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">maxOrder</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">maxNumSources</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">numThreads</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">samplingRate</span> <span class="o">=</span> <span class="n">audioSettings</span><span class="p">.</span><span class="n">samplingRate</span><span class="p">;</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">frameSize</span> <span class="o">=</span> <span class="n">audioSettings</span><span class="p">.</span><span class="n">frameSize</span><span class="p">;</span>
</pre></div>
</div>
<p>For information on the various parameters configured here, see <a class="reference internal" href="simulation.html#ref-simulation"><span class="std std-ref">Simulation</span></a>. Among other things, the above code enables reflection simulation, specifies that up to 4096 rays will be traced from the listener, that the simulation should use 2 threads, and the result of the simulation should be stored in a 4-channel (1st order Ambisonics) impulse response (IR) that is 2.0 seconds long.</p>
</div>
<div class="section" id="simulating-reflections">
<h3>Simulating reflections<a class="headerlink" href="#simulating-reflections" title="Permalink to this headline">¶</a></h3>
<p>To simulate reflections, first specify relevant properties of the source:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationInputs</span> <span class="n">inputs</span><span class="p">{};</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_REFLECTIONS</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">sourceCoordinates</span><span class="p">;</span>

<span class="n">iplSourceSetInputs</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_REFLECTIONS</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">inputs</span><span class="p">);</span>
</pre></div>
</div>
<p>Then, specify global properties of the simulation:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationSharedInputs</span> <span class="n">sharedInputs</span><span class="p">{};</span>
<span class="n">sharedInputs</span><span class="p">.</span><span class="n">listener</span> <span class="o">=</span> <span class="n">listenerCoordinates</span><span class="p">;</span>
<span class="n">sharedInputs</span><span class="p">.</span><span class="n">numRays</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">;</span>
<span class="n">sharedInputs</span><span class="p">.</span><span class="n">numBounces</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span>
<span class="n">sharedInputs</span><span class="p">.</span><span class="n">duration</span> <span class="o">=</span> <span class="mf">2.0f</span><span class="p">;</span>
<span class="n">sharedInputs</span><span class="p">.</span><span class="n">order</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">sharedInputs</span><span class="p">.</span><span class="n">irradianceMinDistance</span> <span class="o">=</span> <span class="mf">1.0f</span><span class="p">;</span>

<span class="n">iplSimulatorSetSharedInputs</span><span class="p">(</span><span class="n">simulator</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_REFLECTIONS</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sharedInputs</span><span class="p">);</span>
</pre></div>
</div>
<p>This specifies that when the simulation is run next, all 4096 rays should be traced from the listener, up to the full 2.0 seconds of IR should be calculated, and all 4 channels should be calculated. The rays should also be bounced up to 16 times. Steam Audio lets you change the number of rays traced, or the length or IR computed, from one simulation to the next; for more details, see <a class="reference internal" href="simulation.html#ref-simulation"><span class="std std-ref">Simulation</span></a>.</p>
<p>Finally, run the simulation and retrieve the results:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// typically run in a separate thread</span>
<span class="n">iplSimulatorRunReflections</span><span class="p">(</span><span class="n">simulator</span><span class="p">);</span>

<span class="c1">// typically run in the main update thread</span>
<span class="n">IPLSimulationOutputs</span> <span class="n">outputs</span><span class="p">{};</span>
<span class="n">iplSourceGetOutputs</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_REFLECTIONS</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">outputs</span><span class="p">);</span>

<span class="n">IPLReflectionEffectParams</span> <span class="n">params</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">reflections</span><span class="p">;</span> <span class="c1">// this can be passed to a reflection effect (see below)</span>
</pre></div>
</div>
</div>
<div class="section" id="rendering-reflections">
<h3>Rendering reflections<a class="headerlink" href="#rendering-reflections" title="Permalink to this headline">¶</a></h3>
<p>To render the results of a reflection simulation, you use an <code class="docutils literal notranslate"><span class="pre">IPLReflectionEffect</span></code> object:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLReflectionEffectSettings</span> <span class="n">effectSettings</span><span class="p">{};</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_REFLECTIONEFFECTTYPE_CONVOLUTION</span><span class="p">;</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">irSize</span> <span class="o">=</span> <span class="mi">88200</span><span class="p">;</span> <span class="c1">// 2.0f (IR duration) * 44100 (sampling rate)</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">numChannels</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span> <span class="c1">// 1st order Ambisonics</span>

<span class="n">IPLReflectionEffect</span> <span class="n">effect</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplReflectionEffectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">audioSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effectSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effect</span><span class="p">);</span>
</pre></div>
</div>
<p>As usual, apply reflections to an audio buffer using <code class="docutils literal notranslate"><span class="pre">iplReflectionEffectApply</span></code>:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">inBuffer</span><span class="p">;</span> <span class="c1">// must be mono</span>
<span class="n">IPLAudioBuffer</span> <span class="n">outBuffer</span><span class="p">;</span> <span class="c1">// must have 4 channels (1st order Ambisonics) for this example</span>

<span class="n">IPLReflectionEffectParams</span> <span class="n">params</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">reflections</span><span class="p">;</span> <span class="c1">// as above</span>
<span class="n">params</span><span class="p">.</span><span class="n">numChannels</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span> <span class="c1">// use all channels of the IR</span>
<span class="n">params</span><span class="p">.</span><span class="n">irSize</span> <span class="o">=</span> <span class="mi">88200</span><span class="p">;</span> <span class="c1">// use the full duration of the IR</span>

<span class="n">iplReflectionEffectApply</span><span class="p">(</span><span class="n">effect</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">params</span><span class="p">,</span> <span class="n">inBuffer</span><span class="p">,</span> <span class="n">outBuffer</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="reverb">
<h3>Reverb<a class="headerlink" href="#reverb" title="Permalink to this headline">¶</a></h3>
<p>Reflection simulation models sound reflecting from the source to the listener. You can also use it to model reverberation within the listener’s space (i.e., independent of any sources) by placing the source at the listener position. This lets you model smoothly-varying, physics-based reverb, with a CPU usage cost that is independent of the number of sources in your scene.</p>
<p>You can also use reflection simulation to model the reverb of the <em>source’s</em> space, by placing the listener at the source position.</p>
</div>
</div>
<div class="section" id="baking">
<h2>Baking<a class="headerlink" href="#baking" title="Permalink to this headline">¶</a></h2>
<p>Simulating reflections in real-time is a very compute-intensive process. So Steam Audio lets you <em>bake</em>, or precompute reflections throughout a scene (or part of a scene) beforehand.</p>
<p>Reflections are baked at several points that you specify. Each of these points is called a <em>probe</em>. Just like game engines use <em>light probes</em> to store the variation of lighting throughout a scene, Steam Audio uses acoustic probes to store the variation of acoustic data (in this case, reflections) throughout a scene.</p>
<div class="section" id="generating-probes">
<h3>Generating probes<a class="headerlink" href="#generating-probes" title="Permalink to this headline">¶</a></h3>
<p>While you can place probes manually, you can also generate them automatically. Probes are generated and placed in <code class="docutils literal notranslate"><span class="pre">IPLProbeArray</span></code> objects:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// this specifies a 100x100x100 axis-aligned box</span>
<span class="n">IPLMatrix4x4</span> <span class="n">boxTransform</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">{</span><span class="mf">100.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">},</span>
    <span class="p">{</span>  <span class="mf">0.0f</span><span class="p">,</span> <span class="mf">100.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">},</span>
    <span class="p">{</span>  <span class="mf">0.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">,</span> <span class="mf">100.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">},</span>
    <span class="p">{</span>  <span class="mf">0.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">,</span>   <span class="mf">0.0f</span><span class="p">,</span>   <span class="mf">1.0f</span><span class="p">}</span>
<span class="p">};</span>

<span class="n">IPLProbeGenerationParams</span> <span class="n">probeParams</span><span class="p">{};</span>
<span class="n">probeParams</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_PROBEGENERATIONTYPE_UNIFORMFLOOR</span><span class="p">;</span>
<span class="n">probeParams</span><span class="p">.</span><span class="n">spacing</span> <span class="o">=</span> <span class="mf">2.0f</span><span class="p">;</span>
<span class="n">probeParams</span><span class="p">.</span><span class="n">height</span> <span class="o">=</span> <span class="mf">1.5f</span><span class="p">;</span>
<span class="n">probeParams</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">boxTransform</span><span class="p">;</span>

<span class="n">IPLProbeArray</span> <span class="n">probeArray</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplProbeArrayCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">probeArray</span><span class="p">);</span>
<span class="n">iplProbeArrayGenerateProbes</span><span class="p">(</span><span class="n">probeArray</span><span class="p">,</span> <span class="n">scene</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">probeParams</span><span class="p">);</span>
</pre></div>
</div>
<p>Probes are then added to <code class="docutils literal notranslate"><span class="pre">IPLProbeBatch</span></code> objects, which are the atomic units in which probes are loaded and unloaded at run-time:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLProbeBatch</span> <span class="n">probeBatch</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplProbeBatchCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">probeBatch</span><span class="p">);</span>
<span class="n">iplProbeBatchAddProbeArray</span><span class="p">(</span><span class="n">probeBatch</span><span class="p">,</span> <span class="n">probeArray</span><span class="p">);</span>
<span class="n">iplProbeBatchCommit</span><span class="p">(</span><span class="n">probeBatch</span><span class="p">);</span>
</pre></div>
</div>
<p>Probe batches can be serialized using <code class="docutils literal notranslate"><span class="pre">iplProbeBatchSave</span></code> and deserialized using <code class="docutils literal notranslate"><span class="pre">iplProbeBatchLoad</span></code>.</p>
</div>
<div class="section" id="baking-reflections">
<h3>Baking reflections<a class="headerlink" href="#baking-reflections" title="Permalink to this headline">¶</a></h3>
<p>For a static source, you can bake reflections that would reach every probe in a probe batch. First, you set up a <em>baked data identifier</em> that specifies what data you want to bake:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLBakeDataIdentifier</span> <span class="n">identifier</span><span class="p">{};</span>
<span class="n">identifier</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_BAKEDDATATYPE_REFLECTIONS</span><span class="p">;</span>
<span class="n">identifier</span><span class="p">.</span><span class="n">variation</span> <span class="o">=</span> <span class="n">IPL_BAKEDDATAVARIATION_STATICSOURCE</span><span class="p">;</span>
<span class="n">identifier</span><span class="p">.</span><span class="n">endpointInfluence</span><span class="p">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">sourcePosition</span><span class="p">;</span> <span class="c1">// world-space position of the source</span>
<span class="n">identifier</span><span class="p">.</span><span class="n">endpointInfluence</span><span class="p">.</span><span class="n">radius</span> <span class="o">=</span> <span class="mf">100.0f</span><span class="p">;</span> <span class="c1">// only bake reflections for probes within 100m of the source</span>
</pre></div>
</div>
<p>Next, specify various parameters to use for baking reflections:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLReflectionsBakeParams</span> <span class="n">bakeParams</span><span class="p">{};</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">scene</span> <span class="o">=</span> <span class="n">scene</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">probeBatch</span> <span class="o">=</span> <span class="n">probeBatch</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">sceneType</span> <span class="o">=</span> <span class="n">IPL_SCENETYPE_DEFAULT</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">identifier</span> <span class="o">=</span> <span class="n">identifier</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">bakeFlags</span> <span class="o">=</span> <span class="n">IPL_REFLECTIONSBAKEFLAGS_BAKECONVOLUTION</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">numRays</span> <span class="o">=</span> <span class="mi">32768</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">numDiffuseSamples</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">numBounces</span> <span class="o">=</span> <span class="mi">64</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">simulatedDuration</span> <span class="o">=</span> <span class="mf">2.0f</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">savedDuration</span> <span class="o">=</span> <span class="mf">2.0f</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">order</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">numThreads</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">irradianceMinDistance</span> <span class="o">=</span> <span class="mf">1.0f</span><span class="p">;</span>
</pre></div>
</div>
<p>Among other things, this specifies that Steam Audio should use a large number of rays (32768), bounce them many times (64 times), and use several threads for simulation (8 in this case). Since baking is an offline preprocess, you will typically use much higher settings for baking than you would for real-time reflection simulation.</p>
<p>Finally, run the bake process:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplReflectionsBakerBake</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">bakeParams</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">);</span>
</pre></div>
</div>
<p>This is a blocking function that returns once the bake is complete. When the bake is complete, you can serialize the probe batch to disk; it will contain the baked reflections data.</p>
</div>
<div class="section" id="using-baked-reflections-data">
<h3>Using baked reflections data<a class="headerlink" href="#using-baked-reflections-data" title="Permalink to this headline">¶</a></h3>
<p>To use baked data at run-time, first load and add the probe batch to your simulator:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLProbeBatch</span> <span class="n">probeBatch</span><span class="p">;</span> <span class="c1">// load from disk</span>

<span class="n">iplSimulatorAddProbeBatch</span><span class="p">(</span><span class="n">simulator</span><span class="p">,</span> <span class="n">probeBatch</span><span class="p">);</span>
<span class="n">iplSimulatorCommit</span><span class="p">(</span><span class="n">simulator</span><span class="p">);</span>
</pre></div>
</div>
<p>Then configure the relevant <code class="docutils literal notranslate"><span class="pre">IPLSource</span></code> object to use the baked data:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationInputs</span> <span class="n">inputs</span><span class="p">{};</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">baked</span> <span class="o">=</span> <span class="n">IPL_TRUE</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">bakedDataIdentifier</span> <span class="o">=</span> <span class="n">identifier</span><span class="p">;</span>
<span class="c1">// set up other properties as usual</span>
</pre></div>
</div>
<p>Steam Audio will then use the baked data from probes in <code class="docutils literal notranslate"><span class="pre">probeBatch</span></code> that are near the listener to estimate the reflections at the listener position.</p>
</div>
</div>
<div class="section" id="pathing">
<h2>Pathing<a class="headerlink" href="#pathing" title="Permalink to this headline">¶</a></h2>
<p>Simulating reflections lets you model how sound propagates from a source to the listener. However, you may need to trace a very large number of rays to ensure that indirect propagation paths are found correctly. This is especially true if the sound has to propagate large distances, bend around corners, or pass through multiple openings.</p>
<p>For this reason, Steam Audio provides an alternative type of simulation: pathing. Pathing involves taking a probe batch, and finding the shortest paths from a source to the listener that travel from one probe to another, without being occluded.</p>
<div class="section" id="baking-pathing-data">
<h3>Baking pathing data<a class="headerlink" href="#baking-pathing-data" title="Permalink to this headline">¶</a></h3>
<p>Since pathing requires probes to be generated, pathing data is typically baked in an offline step:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLBakeDataIdentifier</span> <span class="n">identifier</span><span class="p">{};</span>
<span class="n">identifier</span><span class="p">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">IPL_BAKEDDATATYPE_PATHING</span><span class="p">;</span>
<span class="n">identifier</span><span class="p">.</span><span class="n">variation</span> <span class="o">=</span> <span class="n">IPL_BAKEDDATAVARIATION_DYNAMIC</span><span class="p">;</span>

<span class="n">IPLPathBakeParams</span> <span class="n">bakeParams</span><span class="p">{};</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">scene</span> <span class="o">=</span> <span class="n">scene</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">probeBatch</span> <span class="o">=</span> <span class="n">probeBatch</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">identifier</span> <span class="o">=</span> <span class="n">identifier</span><span class="p">;</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">numSamples</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// trace a single ray to test if one probe can see another probe</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">visRange</span> <span class="o">=</span> <span class="mf">50.0f</span><span class="p">;</span> <span class="c1">// don&#39;t check visibility between probes that are &gt; 50m apart</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">pathRange</span> <span class="o">=</span> <span class="mf">100.0f</span><span class="p">;</span> <span class="c1">// don&#39;t store paths between probes that are &gt; 100m apart</span>
<span class="n">bakeParams</span><span class="p">.</span><span class="n">numThreads</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>

<span class="n">iplPathBakerBake</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">bakeParams</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">,</span> <span class="k">nullptr</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="using-baked-pathing-data">
<h3>Using baked pathing data<a class="headerlink" href="#using-baked-pathing-data" title="Permalink to this headline">¶</a></h3>
<p>To use baked pathing data at run-time, make sure the simulator and the source is configured appropriately:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationSettings</span> <span class="n">simulationSettings</span><span class="p">{};</span>
<span class="n">simulationSettings</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_PATHING</span><span class="p">;</span>
<span class="c1">// configure other parameters as needed</span>

<span class="c1">// ... create the simulator ...</span>

<span class="n">IPLSourceSettings</span> <span class="n">sourceSettings</span><span class="p">{};</span>
<span class="n">sourceSettings</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_PATHING</span><span class="p">;</span>

<span class="c1">// ... create the source ...</span>
</pre></div>
</div>
<p>Just like with baked reflections data, you must configure an <code class="docutils literal notranslate"><span class="pre">IPLSource</span></code> to use baked pathing data:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLSimulationInputs</span> <span class="n">inputs</span><span class="p">{};</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">IPL_SIMULATIONFLAGS_PATHING</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">identifier</span> <span class="o">=</span> <span class="n">identifier</span><span class="p">;</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">pathingProbes</span> <span class="o">=</span> <span class="n">probeBatch</span><span class="p">;</span> <span class="c1">// look for paths within this probe batch</span>
<span class="n">inputs</span><span class="p">.</span><span class="n">pathingOrder</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// paths are rendered as a 1st order Ambisonic sound field</span>

<span class="n">iplSourceSetInputs</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_PATHING</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">inputs</span><span class="p">);</span>
</pre></div>
</div>
<p>Then you can run pathing simulation and retrieve the results:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">iplSimulatorRunPathing</span><span class="p">(</span><span class="n">simulator</span><span class="p">);</span>

<span class="n">IPLSimulationOutputs</span> <span class="n">outputs</span><span class="p">{};</span>
<span class="n">iplSourceGetOutputs</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">IPL_SIMULATIONFLAGS_PATHING</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">outputs</span><span class="p">);</span>

<span class="n">IPLPathEffectParams</span> <span class="n">params</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">pathing</span><span class="p">;</span> <span class="c1">// see below</span>
</pre></div>
</div>
<p>Since pathing data is baked, the paths assume all geometry is static. You can also configure Steam Audio to re-check paths for occlusion by dynamic geometry, and optionally, to find alternate paths around the dynamic occluders. For more information, see <a class="reference internal" href="simulation.html#ref-simulation"><span class="std std-ref">Simulation</span></a>.</p>
</div>
<div class="section" id="rendering-paths">
<h3>Rendering paths<a class="headerlink" href="#rendering-paths" title="Permalink to this headline">¶</a></h3>
<p>Sound arriving at the listener via indirect paths found by pathing simulation is rendered as an Ambisonic sound field. This rendering is performed using an <code class="docutils literal notranslate"><span class="pre">IPLPathEffect</span></code> object:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLPathEffectSettings</span> <span class="n">effectSettings</span><span class="p">{};</span>
<span class="n">effectSettings</span><span class="p">.</span><span class="n">maxOrder</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// render up to 1st order Ambisonic sound fields</span>

<span class="n">IPLPathEffect</span> <span class="n">effect</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
<span class="n">iplPathEffectCreate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">audioSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effectSettings</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">effect</span><span class="p">);</span>
</pre></div>
</div>
<p>The results of pathing simulation can then be passed to <code class="docutils literal notranslate"><span class="pre">iplPathEffectApply</span></code>:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">IPLAudioBuffer</span> <span class="n">inBuffer</span><span class="p">;</span> <span class="c1">// must be mono</span>
<span class="n">IPLAudioBuffer</span> <span class="n">outBuffer</span><span class="p">;</span> <span class="c1">// must have 4 channels (1st order Ambisonics) in this example</span>

<span class="n">IPLPathEffectParams</span> <span class="n">params</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">pathing</span><span class="p">;</span> <span class="c1">// as above</span>
<span class="n">params</span><span class="p">.</span><span class="n">order</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="c1">// render all 4 channels</span>

<span class="n">iplPathEffectApply</span><span class="p">(</span><span class="n">effect</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">params</span><span class="p">,</span> <span class="n">inBuffer</span><span class="p">,</span> <span class="n">outBuffer</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="integration.html" class="btn btn-neutral float-right" title="Integrating Steam Audio" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="getting-started.html" class="btn btn-neutral float-left" title="Getting Started" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Valve Corporation.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>